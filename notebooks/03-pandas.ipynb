{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise e manipulação de dados\n",
    "\n",
    "Os arrays definidos pela biblioteca [NumPy](https://numpy.org/) fornecem funcionalidades essenciais para processamento numérico eficiente em Python. No entanto, estes foram desenhados para lidar com os tipos de conjuntos de dados limpos e bem organizados que são tipicamente usados no contexto de tarefas de computação numérica. No contexto da descoberta e extração de conhecimento de dados, é comum lidar com dados menos estruturados, heterogéneos e que podem ter valores em falta. As limitações dos arrays para a análise e manipulação deste tipo de dados tornam-se rapidamente evidentes. A biblioteca [pandas](https://pandas.pydata.org/) aborda essas limitações, fornecendo uma implementação eficiente de uma tabela de dados (`DataFrame`). As tabelas de dados são basicamente arrays multidimensionais associados a etiquetas para as linhas e colunas e capazes de lidar com tipos heterogéneos e valores em falta. Para além disso, a biblioteca *pandas* implementa várias operações sobre dados que são familiares para os utilizadores de bases de dados e folhas de cálculo. Como as estruturas de dados definidas pela biblioteca *pandas* são construídas em cima de arrays *NumPy*, estas operações são efetuadas de forma eficiente. Isto faz da biblioteca uma ferramenta importante para realizar as tarefas de manipulação de dados que ocupam grande parte do tempo de um cientista de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estruturas de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A um nível muito básico, as estruturas de dados definidas pela biblioteca *pandas* podem ser vistas como versões melhoradas de arrays *NumPy* nas quais as linhas e colunas são identificadas por etiquetas em vez de um índice baseado na posição. As três estruturas de dados fundamentais definidas pela biblioteca *pandas* são a série (`Series`), a tabela de dados (`DataFrame`) e o índice (`Index`). O índice é uma estrutura interessante por si só, que pode ser vista como um array imutável ou como um conjunto ordenado. No entanto, a sua relevancia deve-se ao seu uso no contexto das outras duas estruturas. Por isso, para simplificar, vamos focar nessas duas e olhar para o índice como algo semelhante a um array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Série (`Series`)\n",
    "\n",
    "Uma série é um array unidimensional de dados indexados. \n",
    "\n",
    "Séries podem ser criadas de várias formas. Por exemplo, a partir de sequências (ex: listas ou arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma série combina uma sequência de valores e uma sequência explícita de índices, que podem ser acedidas individualmente através dos atributos `values`e `index`, respetivamente. Os valores são guardados como um array *NumPy*, enquanto os índices são guardados num objeto do tipo `Index` (ou uma das suas subclasses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como nos arrays, é possível aceder aos dados de uma série usando o operador de indexação `[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Até agora, uma série parece ser a mesma coisa que um array *NumPy* unidimensional. No entanto, existe uma diferença essencial: enquanto o array tem um índice inteiro definido implicitamente que é usado para aceder aos valores, a série tem um índice definido explicitamente que é associado aos valores. Esta definição explícita do índice confere capacidades adicionais à série. Por exemplo, o índice pode consistir em valores de qualquer tipo e não apenas inteiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independentemente do tipo, o operador de indexação continua a funcionar da mesma forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores do índice nem sequer necessitam de ser contíguos ou sequenciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0], index=[2, 5, 3, 7])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta perspetiva, uma série pode ser vista como uma especialização de um dicionário. Em Python, um dicionário é uma estrutura que mapeia chaves arbitrárias num conjunto de valores arbitrários. Uma série é uma estrutura que mapeia chaves de um determinado tipo num conjunto de valores que também têm um tipo definido. Esta tipificação é importante pela mesma razão que no caso dos arrays *NumPy*: eficiência das operações realizadas sobre a estrutura.\n",
    "\n",
    "A analogia da série como um dicionário torna-se ainda mais clara ao construir uma série diretamente a partir de um dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "population_dict = {\n",
    "    'California': 39538223,\n",
    "    'Texas': 29145505,\n",
    "    'Florida': 21538187,\n",
    "    'New York': 20201249,\n",
    "    'Pennsylvania': 13002700\n",
    "}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, o índice é construído a partir do conjunto de chaves do dicionário. O acesso ao valor associado a um índice/chave é feito da mesma forma que num dicionário:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "population['California']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, ao contrário de um dicionário, uma série também permite obter todos os valores entre dois índices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "population['California':'Florida']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Ao criar uma série a partir de um dicionário, é possível explicitar a ordem e/ou um subconjunto de chaves a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({2: 'a', 1: 'b', 3: 'c'}, index=[1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Também é possível criar uma série com um valor constante para todos os índices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(5, index=['John', 'Jane', 'Mary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela de dados (`DataFrame`)\n",
    "\n",
    "Uma tabela de dados é uma sequência de séries que partilham o mesmo índice. Tal como uma série, uma tabela de dados pode ser vista como uma generalização de um array *NumPy* ou como uma especialização de um dicionário. Para exemplificar a criação de uma tabela de dados, vamos começar por criar uma série com as áreas dos estados dos EUA para combinar com a série da população desses estados que criamos anteriormente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "area_dict = {\n",
    "    'California': 423967,\n",
    "    'Texas': 695662,\n",
    "    'Florida': 170312,\n",
    "    'New York': 141297,\n",
    "    'Pennsylvania': 119280\n",
    "}\n",
    "\n",
    "area = pd.Series(area_dict)\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar a tabela de dados, podemos usar um dicionário que associa uma etiqueta a cada uma das séries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'population': population, 'area': area})\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como uma série, uma tabela de dados tem um atributo `index` que permite aceder ao índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para além disso, uma tabela de dados tem um atributo `columns` que permite aceder a um índice com as etiquetas das colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo, uma tabela de dados pode ser vista como uma generalização de um array bidimensional em que quer as linhas, quer as colunas têm um índice explícito que pode ser usado para aceder aos dados. Para além disso, uma tabela de dados também pode ser vista como uma especialização de um dicionário em que as etiquetas das colunas são mapeadas nas séries de dados correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "states['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para além de um dicionário que associa uma etiqueta a cada uma das séries, podemos criar tabelas de dados de outras formas. Por exemplo, a partir de uma única série:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(population, columns=['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível criar uma tabela de dados a partir de um array bidimensional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2), columns=['foo', 'bar'], index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Neste caso, se um dos ou ambos os índices não forem explicitados, são usados os índices inteiros do array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.random.rand(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra opção é criar uma tabela de dados a partir de uma lista de dicionários em que cada um deles representa uma entrada (linha) na tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = [{'a': i, 'b': 2 * i} for i in range(3)]\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Ao criar uma tabela de dados, se os índices das séries ou as chaves das entradas não coincidirem, então a tabela vai ter valores em falta, representados por `NaN`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(np.random.rand(3), index=['a', 'b', 'c'])\n",
    "s2 = pd.Series(np.random.rand(3), index=['a', 'd', 'c'])\n",
    "\n",
    "pd.DataFrame({'s1': s1, 's2': s2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações sobre tabelas de dados\n",
    "\n",
    "A biblioteca *pandas* oferece uma vasta gama de métodos e operações para análise e manipulação de dados a vários níveis. Grande parte do conhecimento sobre essas funcionalidades vai sendo adquirido com a prática e a experiência de lidar os problemas colocados por diferentes conjuntos de dados. Não se espera que alguém domine todas as funcionalidades e é comum consultar a [documentação da biblioteca](https://pandas.pydata.org/docs/index.html) para resolver problemas específicos. No entanto, inicialmente, é importante adquirir uma noção de como usar as operações básicas de transformação de dados e análise estatística, de forma a conseguir dar os primeiros passos na análise e manipulação de conjuntos de dados. \n",
    "\n",
    "Como exemplo, vamos olhar para um conjunto de dados com informação sobre filmes extraída da [IMDb](https://www.imdb.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = '../data/' if os.path.exists('../data/') else 'https://raw.githubusercontent.com/TheAwesomeGe/DECD/main/data/'\n",
    "\n",
    "movies_df = pd.read_csv(data_path + 'IMDB-Movie-Data.csv', index_col='Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, usamos o método `read_csv` para carregar o dataset de um ficheiro CSV e usar os títulos dos filmes como índice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: A biblioteca *pandas* define métodos para carregar datasets em vários formatos, como por exemplo a partir de uma folha de Excel (`read_excel`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar os dados\n",
    "\n",
    "A primeira coisa a fazer ao abrir um novo conjunto de dados é olhar para os nomes das colunas e para algumas entradas para ter uma ideia do tipo de informação que é fornecida pelo conjunto de dados.\n",
    "\n",
    "A representação predefinida do tipo `DataFrame` mostra as 5 primeiras e as 5 últimas entradas do conjunto de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, podemos usar os métodos `head` e `tail` para ver as primeiras ou últimas *n* entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Se não for explicitado o número de entradas a mostrar, estes métodos mostram 5 entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obter informação sobre os dados\n",
    "\n",
    "O método `info` fornece os detalhes essenciais sobre um conjunto de dados, como o número de linhas e colunas, o número de valores não nulos, o tipo de dados em cada coluna e a quantidade de memória ocupada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, facilmente conseguimos perceber que as colunas `Revenue (Millions)` e `Metascore` têm valores em falta.\n",
    "\n",
    "Conseguir saber os tipos de cada coluna rapidamente é muito útil. Por exemplo, permite perceber se alguns dados foram carregados com o tipo errado (ex: inteiros como cadeias de caracteres).\n",
    "\n",
    "O atributo `shape` também pode ser usado para descobrir rapidamente o número de entradas e atributos de um conjunto de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza de colunas\n",
    "\n",
    "Muitas vezes, os conjuntos de dados contêm colunas que não são úteis no contexto do problema que está a ser abordado. Para além disso, é normal as colunas terem nomes verbosos, com símbolos, capitalização variável, espaços, erros, etc.\n",
    "\n",
    "Para simplificar a análise dos dados e o processo de seleção baseado nos nomes das colunas, podemos fazer alguma limpeza.\n",
    "\n",
    "Como vimos anteriormente, podemos aceder ao índice com os nomes das colunas de uma tabela de dados usando o atributo `columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este atributo é útil quando queremos renomear ou descartar colunas, pois permite copiar e colar os nomes das colunas em que estamos interessados. Para além disso, também é útil para perceber porque é que obtivemos um `KeyError` ao tentar selecionar alguns dados com base no nome de uma coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['Revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É prática comum renomear as colunas para que os nomes sejam em minúsculas, não contenham caracteres especiais e os espaços sejam substituídos por *underscore*. \n",
    "\n",
    "Podemos usar o método `rename` para renomear algumas ou todas as colunas usando um dicionário. Vamos usar essa abordagem para remover os parênteses dos nomes das colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.rename(columns={\n",
    "    'Runtime (Minutes)': 'Runtime', \n",
    "    'Revenue (Millions)': 'Revenue_millions'\n",
    "}, inplace=True)\n",
    "\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: O argumento `inplace` serve para definir se queremos alterar diretamente a tabela de dados ou obter uma nova tabela com o resultado da aplicação da operação. O comportamento predefinido é não alterar a tabela original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos atribuir diretamente uma nova lista de etiquetas ao atributo `columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns = [\n",
    "    'rank', 'genre', 'description', \n",
    "    'director', 'actors', 'year', \n",
    "    'runtime', 'rating', 'votes', \n",
    "    'revenue_millions', 'metascore'\n",
    "]\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Há uma maneira mais rápida de mudar todos os nomes para minúsculas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.columns = [c.lower() for c in movies_df.columns]\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compreensões de lista (e dicionário) são muito úteis em conjunto com as operações da biblioteca *pandas* e ao trabalhar com dados no geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para selecionar o conjunto de colunas que nos interessa, podemos usar o operador de indexação `[]` com uma lista dos nomes das colunas que queremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = movies_df[['genre', 'director', 'year', 'runtime', 'rating', 'votes', 'revenue_millions', 'metascore']]\n",
    "selected_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, podemos descartar as colunas que não nos interessam usando o método `drop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.drop(columns=['rank', 'description', 'actors'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores em falta\n",
    "\n",
    "Ao explorar um conjunto de dados, é possível encontrar valores em falta ou nulos. As representações mais comuns para estes valores desconhecidos ou não existententes são `None` ou `numpy.NaN`.\n",
    "\n",
    "As abordagens mais comuns para lidar com valores em falta são:\n",
    "\n",
    "1. Apagar as linhas ou colunas com valores em falta\n",
    "2. Prencher os valores em falta com valores obtidos usando uma técnica chamada imputação\n",
    "\n",
    "Para calcular o número de valores em falta num conjunto de dados, podemos começar por verificar quais as células da tabela de dados que têm uma das representações para valores desconhecidos. Para isso, podemos usar o método `isnull`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método devolve uma tabela de dados em que cada célula tem um valor booleano que indica se o valor está em falta. Por si só isto não é muito útil. No entanto, podemos usar uma função de agregação, neste caso a soma (`sum`), para obter um resultado mais interessante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim podemos concluir que existem **128** valores em falta na coluna `revenue_millions` e **64** valores em falta na coluna `metascore`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remoção de valores em falta\n",
    "\n",
    "Cientistas e analistas de dados são regularmente confrontados com o dilema de descartar ou imputar valores em falta. Esta é uma decisão que requer conhecimento dos dados e do contexto em que eles são utilizados. No entanto, normalmente, só é recomendada a remoção das entradas com valores em falta quando estas representam uma porção insignificante do conjunto de dados total. Pelo contrário, só é recomendada a remoção de atributos com valores em falta quando estes estão em maioria. \n",
    "\n",
    "O método `dropna` pode ser usado para descartar valores em falta de uma tabela de dados. O comportamento predefinido é apagar todas as **entradas** que têm pelo menos um valor em falta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso deste conjunto de dados, seriam removidas `1000 - 838 = 162` entradas ao aplicar esta operação. Isto é um desperdício, uma vez que existem dados que podem ser importantes nas outras colunas dessas entradas.\n",
    "\n",
    "Para descartar atributos com valores em falta podemos usar o método `dropna` com o argumento `axis='columns'` ou `axis=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, são mantidas as 1000 entradas, mas as colunas `revenue_millions` e `metascore` são removidas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputação\n",
    "\n",
    "Imputação (o processo de substituir valores em falta por valores representativos) é uma técnica convencional de engenharia de atributos usada para evitar descartar entradas com valores em falta. Na prática, consiste em substituir os valores em falta por valores representativos, como por exemplo a média ou a mediana do atributo no conjunto de dados.\n",
    "\n",
    "Como exemplo, vamos usar esta estratégia para lidar com os valores em falta na coluna `revenue_millions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = movies_df['revenue_millions']\n",
    "revenue_mean = revenue.mean()\n",
    "revenue_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos a média, podemos usar o método `fillna` para preencher os valores em falta com esse valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue.fillna(revenue_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: O método foi chamado sobre a série `revenue` pois só queremos preencher os valores em falta para esse atributo e não todos os valores em falta na tabela de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Imputar uma todos os valores em falta de uma coluna com o mesmo valor é um exemplo básico da aplicação técnica. Uma ideia melhor seria usar uma imputação mais granular. Por exemplo, podiamos calcular a média para cada género de filme ou para cada realizador e usar esses valores para preencher os valores em falta em entradas com as mesmas características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `describe` pode ser usado para obter um resumo da distribuição dos atributos contínuos de uma tabela de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `describe` também pode ser aplicado sobre uma série. Se essa série representar um atributo categórico, a informação obtida consiste no número de entradas, número de valores diferentes, qual o valor mais comum e a frequência desse valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genre'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto diz-nos que a coluna `genre` tem 207 valores diferentes, sendo o mais comum `Action/Adventure/Sci-Fi`, que aparece 50 vezes.\n",
    "\n",
    "O método `value_counts` pode ser usado para obter a frequência dos valores numa coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genre'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `corr` pode ser usado para analisar a correlação entre cada par de atributos contínuos no conjunto de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Números positivos indicam uma correlação positiva (quando um aumenta, o outro também aumenta) e números negativos indicam uma correlação inversa (quando um aumenta, o outro decresce). O valor 1.0 indica uma correlação perfeita.\n",
    "\n",
    "Olhando para a tabela de correlações, podemos, por exemplo, ver que cada variável tem uma correlação perfeita consigo própria. No entanto, esta informação é óbvia e, por isso, pouco interessante. Por outro lado, uma correlação de 0.6 entre as variáveis `votes` e `revenue_millions` é uma observação mais interessante. \n",
    "\n",
    "Analisar tabelas de correlação entre atributos é útil, por exemplo, para identificar quais os atributos mais relacionados com um outro atributo de interesse. Entre outras coisas, esta informação pode depois ser usada para fazer uma seleção de atributos para reduzir a dimensionalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de dados\n",
    "\n",
    "Já vimos anteriormente que podemos selecionar dados com base no nome das colunas/atributos. Se usarmos o operador de indexação `[]` com o nome duma coluna, obtemos a série corresponde. Se usarmos uma lista, obtemos uma tabela de dados com as colunas incluídas na lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = movies_df['genre']\n",
    "type(genre_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_col = movies_df[['genre']]\n",
    "type(genre_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível selecionar linhas/entradas específicas. Para isso existem dois métodos:\n",
    "\n",
    "- `loc` - seleciona por nome (valor do índice)\n",
    "- `iloc`- seleciona por posição numérica no índice\n",
    "\n",
    "O nosso conjunto de dados está indexado pelo título dos filmes. Por isso, podemos usar o método `loc` para obter a entrada correspondente ao filme com um determinado título:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.loc['Prometheus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obter a mesma entrada usando o método `iloc` com a posição do filme no índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estes métodos também podem ser usados para obter uma sequência de entradas contíguas da mesma forma que numa lista ou array *NumPy*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.loc['Prometheus':'Sing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Uma distinção importante entre os dois métodos quando são usados para obter múltiplas entradas é que num deles o intervalo é aberto à direita e no outro é fechado. No caso do método `iloc`, o intervalo é aberto à direita, tal como na indexação de listas e arrays. Por isso, o filme na posição 4 não foi selecionado. No caso do método `loc`, o intervalo é fechado. Por isso, o filme Sing foi selecionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante saber selecionar atributos ou entradas específicas, mas mais interessante que isso é conseguir selecionar dados que satisfazem uma determinada condição. Por exemplo, filmes realizados pelo Ridley Scott ou filmes com uma classificação igual ou superior a 8.0.\n",
    "\n",
    "Para fazer seleções deste tipo, podemos aplicar condições booleanas sobre as colunas de uma tabela de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_movies = movies_df['director'] == 'Ridley Scott'\n",
    "rs_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado da aplicação duma condição deste tipo é semelhante ao obtido quando aplicamos o método `isnull`. Neste caso temos uma série de valores booleanos que indicam se o Ridley Scott é o realizador de cada um dos filmes. \n",
    "\n",
    "Podemos usar métodos de agregação sobre este resultado para descobrir, por exemplo, quantos dos filmes foram realizados pelo Ridley Scott:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_movies.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas o nosso objectivo era obter as entradas correspondentes aos filmes realizados pelo Ridley Scott...\n",
    "\n",
    "Para isso, temos de usar a condição (ou o resultado dela) com o operador de indexação sobre a tabela de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[rs_movies].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['director'] == 'Ridley Scott'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem está habituado a trabalhar com bases de dados SQL, pode ajudar interpretar este tipo de seleção como:\n",
    "\n",
    "> select * from movies_df where director = Ridley Scott\n",
    "\n",
    "As condições também podem ser aplicadas sobre atributos numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['rating'] >= 8.6].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível fazer seleções mais complexas recorrendo aos operadores lógicos `|` (ou) e `&` (e).\n",
    "\n",
    "Por exemplo, podemos selecionar filmes realizados pelo Ridley Scott OU pelo Christopher Nolan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[(movies_df['director'] == 'Ridley Scott') | (movies_df['director'] == 'Christopher Nolan')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: A utilização de parênteses à volta de cada condição é necessária para o interpretador de Python saber avaliar corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mesma seleção pode ser feita de forma mais simples usando o método `isin`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['director'].isin(['Christopher Nolan', 'Ridley Scott'])].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seleções condicionais podem envolver condições sobre várias colunas e usar estatísticas dos dados, o que as torna muito poderosas. Por exemplo, é possível selecionar filmes que estrearam entre 2005 e 2010 e com uma classificação acima de 8.0, mas que tiveram uma receita abaixo da média:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\n",
    "    ((movies_df['year'] >= 2005) & (movies_df['year'] <= 2010))\n",
    "    & (movies_df['rating'] > 8.0)\n",
    "    & (movies_df['revenue_millions'] < movies_df['revenue_millions'].mean())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação de atributos\n",
    "\n",
    "Existem múltiplas razões que levam à necessidade de transformar os atributos de conjunto de dados de alguma forma. Por exemplo:\n",
    "\n",
    "- A representação de um determinado atributo não é a mais adequada no contexto do problema que queremos abordar\n",
    "- As abordagens de extração de conhecimento que queremos aplicar não são compatíveis com um determinado tipo de atributo\n",
    "- Queremos agrupar atributos ou gerar novos atributos com base nos existentes\n",
    "\n",
    "Como exemplo, vamos transformar o atributo `rating` num atributo categórico que tem o valor `'good'` se a classificação for igual ou superior a 8.0 e o valor `'bad'` caso contrário. Para isso, vamos começar por criar a função que faz essa transformação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_function(x):\n",
    "    if x >= 8.0:\n",
    "        return 'good'\n",
    "    else:\n",
    "        return 'bad'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível iterar sobre uma série ou tabela de dados da mesma forma que sobre uma lista e usar essa abordagem para aplicar a função a todas as entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([rating_function(r) for r in movies_df['rating']], index=movies_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, essa é uma operação que se torna lenta em conjuntos de dados de grande dimensão. Uma alternativa mais eficiente é usar o método `apply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['rating'].apply(rating_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: O método `apply` é mais eficiente pois usa vetorização, isto é, a função é aplicada a todas as entradas de uma só vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para adicionar o novo atributo ou substituir o existente, podemos usar a analogia da tabela de dados como um dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['rating_category'] = movies_df['rating'].apply(rating_function)\n",
    "movies_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Muitas vezes é útil usar uma função anónima como argumento do método `apply`. Estas têm a sintaxe `lambda <argumentos>: <expressão>`. Por exemplo, a transformação anterior também poderia ser feita da seguinte forma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['rating'].apply(lambda x: 'good' if x >= 8.0 else 'bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exemplificar a criação de um novo atributo a partir de uma combinação dos existentes, vamos gerar um novo atributo que diz a variação entre as duas classificações de um filme (`rating` e `metascore`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide the metascore by 10 so that both ratings are in the same scale\n",
    "movies_df['rating_difference'] = movies_df.apply(lambda x: x['rating'] - x['metascore']/10, axis='columns')  \n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, estamos a aplicar o método `apply` sobre a tabela de dados e a explicitar o argumento `axis='columns'` de forma a ter acesso a todos os atributos e podermos usá-los na geração do novo atributo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Uma área em que o método `apply` é usado exaustivamente é o processamento de língua natural. Nesse contexto é necessário aplicar uma panóplia de funções de limpeza e manipulação de texto para preparar os dados para aplicação de abordagens de aprendizagem automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais\n",
    "\n",
    "A capacidade de analisar, explorar, transformar e visualizar dados é essencial na ciência de dados. Os vários passos deste processo ocupam uma grande parte do tempo de quem trabalha nesta área. Como tal, é importante que seja possível reproduzir de forma fácil o processo de análise e manipulação feito sobre um determinado conjunto de dados e/ou que, pelo menos, o seu resultado seja guardado. \n",
    "\n",
    "Tal como para a leitura de conjuntos de dados em vários formatos, a biblioteca *pandas* fornece um conjunto de métodos para guardar conjuntos de dados nesses mesmos formatos. Por exemplo, podemos usar o método `to_csv` para guardar o nosso conjunto de dados processado num ficheiro CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.to_csv('IMDB-Movie-Data-Processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como referido anteriormente, a biblioteca *pandas* oferece uma vasta gama de métodos e operações para análise e manipulação de dados a vários níveis. Neste tutorial cobrimos apenas uma pequena parte da funcionalidade disponibilizada pela biblioteca: a funcionalidade básica que é usada em quase todas as tarefas de análise e manipulação de dados. Para explorar alguns temas mais a fundo, recomendamos os [tutoriais da biblioteca pandas](https://pandas.pydata.org/pandas-docs/stable/tutorials.html) e o [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
